{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a6694798fa4434966ca84b40ee6f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1597012298810_0178</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-81-94.ec2.internal:20888/proxy/application_1597012298810_0178/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-80-185.ec2.internal:8042/node/containerlogs/container_1597012298810_0178_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.3.0\n",
      "  Using cached https://files.pythonhosted.org/packages/1c/15/3fea1bfb7e5b77b7cca9c6010a9cabc58ea125385345ecb6f5832eb8b49a/matplotlib-3.3.0-1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib64/python3.7/site-packages (from matplotlib==3.3.0)\n",
      "Collecting python-dateutil>=2.1 (from matplotlib==3.3.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 (from matplotlib==3.3.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting pillow>=6.2.0 (from matplotlib==3.3.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/f2/6722dd0c22e3a143ac792ccb2424924ac72af4adea756b1165b4cad50da7/Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting cycler>=0.10 (from matplotlib==3.3.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.3.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/31/b9/6202dcae729998a0ade30e80ac00f616542ef445b088ec970d407dfd41c0/kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib==3.3.0)\n",
      "Installing collected packages: python-dateutil, pyparsing, pillow, cycler, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.0 pillow-7.2.0 pyparsing-2.4.7 python-dateutil-2.8.1\n",
      "\n",
      "Collecting pandas==0.24.2\n",
      "  Using cached https://files.pythonhosted.org/packages/22/e6/2d47835f91eb010036be207581fa113fb4e3822ec1b4bafb0d3d105fede6/pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib64/python3.7/site-packages (from pandas==0.24.2)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/site-packages (from pandas==0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /mnt/tmp/1597022843132-0/lib/python3.7/site-packages (from pandas==0.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas==0.24.2)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-0.24.2\n",
      "\n",
      "Requirement already satisfied: tensorflow==1.14.0 in /usr/lib64/python3.7/site-packages\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /mnt/tmp/1597022843132-0/lib/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/lib64/python3.7/site-packages (from tensorflow==1.14.0)\n",
      "Requirement already satisfied: setuptools in /mnt/tmp/1597022843132-0/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14.0)\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow==1.14.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-2.10.0\n",
      "\n",
      "Collecting sklearn\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting scipy>=0.19.1 (from scikit-learn->sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/f9/f7a7e5009711579c72da2725174825e5056741bf4001815d097eef1b2e17/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.7/site-packages (from scikit-learn->sklearn)\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/51/dd/0e015051b4a27ec5a58b02ab774059f3289a94b0906f880a3f9507e74f38/joblib-0.16.0-py3-none-any.whl\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Installing collected packages: scipy, joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.16.0 scikit-learn-0.23.2 scipy-1.5.2 sklearn-0.0 threadpoolctl-2.1.0"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"matplotlib==3.3.0\")\n",
    "sc.install_pypi_package(\"pandas==0.24.2\")\n",
    "sc.install_pypi_package(\"tensorflow==1.14.0\")\n",
    "sc.install_pypi_package(\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d06e82d3c44d4e976dd43e4a8c82f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import urllib\n",
    "import operator\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import Window\n",
    "from pyspark import SQLContext\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c90efa2b3e4c50acd07121896b39b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Used for normalizing and scaling close prices\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e7a50b96b3465b8a8badc0dd0b76c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating pySpark Context \n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Loading data from mounted s3 bucket\n",
    "data = sqlContext.read.options(header = 'true', inferschema = 'true').csv(\"s3://bigdatasu20/all_stocks_5yr.csv\")\n",
    "\n",
    "# Selecting American Airlines Data\n",
    "aal = data.filter(\"Name == 'AAL'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126b4a329b5f4e82ae600443b4f0e61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For Visualization of close prices with data\n",
    "df = aal.toPandas()\n",
    "\n",
    "df.loc[:, 'date'] = pd.to_datetime(df.loc[:,'date'], format=\"%Y/%m/%d\")\n",
    "df = df.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-79b540901ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (18,9))\n",
    "plt.plot(range(df.shape[0]),df['close'])\n",
    "plt.xticks(range(0,df.shape[0],50),df['date'].loc[::50],rotation=60)\n",
    "plt.xlabel('Date',fontsize=18)\n",
    "plt.ylabel('Closing price',fontsize=18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecting only close prices for predicition and converting them in to numpy array\n",
    "close_list = aal.select('close').collect()\n",
    "close_price = [row['close'] for row in close_list]\n",
    "close_prices = np.array(close_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scaling close prices \n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(close_prices.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Size of Dataset 1259\n",
       "Size of Training Dataset 1007\n",
       "Size of Testing Dataset 252\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating the split time to split train and test data\n",
    "size = int(len(close_prices))\n",
    "print(\"Size of Dataset\", size)\n",
    "\n",
    "# 80% train and 20% test data\n",
    "split_time = int(size * 80 / 100)\n",
    "\n",
    "print(\"Size of Training Dataset\", split_time)\n",
    "print(\"Size of Testing Dataset\", size - split_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing close prices so that all values are between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "window_length = 50\n",
    "for di in range(0, size, window_length):\n",
    "    scaler.fit(standardized_data[di:di + window_length,:])\n",
    "    standardized_data[di:di + window_length,:] = scaler.transform(standardized_data[di:di + window_length,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshaping in to original data\n",
    "scaled_data = standardized_data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Smoothing using exponential moving average\n",
    "exp_moving_avg = 0.0\n",
    "gamma = 0.1\n",
    "for i in range(split_time):\n",
    "  exp_moving_avg = gamma * scaled_data[i] + (1-gamma)*exp_moving_avg\n",
    "  scaled_data[i] = exp_moving_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data in to train and test sets\n",
    "trainingData = scaled_data[:split_time]\n",
    "testingData = scaled_data[split_time:]\n",
    "\n",
    "# Concatinating for visualization purposes\n",
    "closingData = np.concatenate([trainingData,testingData],axis=0)\n",
    "\n",
    "plt.figure(figsize = (18,9))\n",
    "plt.plot(closingData, label='Scaled Close')\n",
    "plt.xticks(range(0,df.shape[0],50),df['date'].loc[::50],rotation=60)\n",
    "plt.xlabel('Date',fontsize=18)\n",
    "plt.ylabel('Closing price',fontsize=18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Generator is used for training model\n",
    "class DataGen(object):\n",
    "\n",
    "    def __init__(self,prices, sizeOfBatch, numOfTimeSteps):\n",
    "        self._Prices = prices\n",
    "        self._pricesLength = len(self._Prices) - numOfTimeSteps\n",
    "        self._sizeOfBatch = sizeOfBatch\n",
    "        self._numOfTimeSteps = numOfTimeSteps\n",
    "        self._batches = self._pricesLength // self._sizeOfBatch\n",
    "        self._pointer = [_val * self._batches for _val in range(self._sizeOfBatch)]\n",
    "\n",
    "    def upcomingBatch(self):\n",
    "\n",
    "        batchData = np.zeros((self._sizeOfBatch),dtype=np.float32)\n",
    "        batchLabels = np.zeros((self._sizeOfBatch),dtype=np.float32)\n",
    "\n",
    "        for b in range(self._sizeOfBatch):\n",
    "            if self._pointer[b]+1>=self._pricesLength:\n",
    "                self._pointer[b] = np.random.randint(0,(b+1)*self._batches)\n",
    "\n",
    "            batchData[b] = self._Prices[self._pointer[b]]\n",
    "            batchLabels[b]= self._Prices[self._pointer[b]+np.random.randint(0,5)]\n",
    "\n",
    "            self._pointer[b] = (self._pointer[b]+1)%self._pricesLength\n",
    "\n",
    "        return batchData, batchLabels\n",
    "\n",
    "#   This method unpack_future_batches will unpack batches of close prices data\n",
    "    def unpack_future_batches(self):\n",
    "\n",
    "        unpackData, unpackLabels = [],[]\n",
    "        init_data, init_label = None,None\n",
    "        for ui in range(self._numOfTimeSteps):\n",
    "\n",
    "            data, labels = self.upcomingBatch()    \n",
    "\n",
    "            unpackData.append(data)\n",
    "            unpackLabels.append(labels)\n",
    "\n",
    "        return unpackData, unpackLabels\n",
    "\n",
    "    def resetIndices(self):\n",
    "        for b in range(self._sizeOfBatch):\n",
    "            self._pointer[b] = np.random.randint(0,min((b+1)*self._batches,self._pricesLength-1))\n",
    "\n",
    "generatedData = DataGen(trainingData,5,5)\n",
    "data_, labels_ = generatedData.unpack_future_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters for LSTM model\n",
    "D = 1\n",
    "futureTimeSteps = 50\n",
    "sizeOfBatch = 25\n",
    "hiddenNodeCount = [256, 256, 128]\n",
    "# Number of hidden layers\n",
    "layerCount = len(hiddenNodeCount) \n",
    "# Dropuout Probability\n",
    "dropout = 0.25\n",
    "\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We have to enable eager execution to enable some of the features\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Input data\n",
    "trainingInputs = []\n",
    "trainingOutputs = []\n",
    "\n",
    "for i in range(futureTimeSteps):\n",
    "    trainingInputs.append(tf.compat.v1.placeholder(tf.float32, shape=[sizeOfBatch,D],name='trainingInputs%d'%i))\n",
    "    trainingOutputs.append(tf.compat.v1.placeholder(tf.float32, shape=[sizeOfBatch,1], name = 'trainingOutputs%d'%i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining LSTM cell\n",
    "LSTMCells = [\n",
    "    tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=hiddenNodeCount[i],\n",
    "                            state_is_tuple=True,\n",
    "                            initializer= tf.contrib.layers.xavier_initializer()\n",
    "                           )\n",
    " for i in range(layerCount)]\n",
    "\n",
    "\n",
    "# Using dropout LSTM cells to reduce overfitting\n",
    "dropLSTMCells = [tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm, input_keep_prob=1.0, output_keep_prob=1.0-dropout, state_keep_prob=1.0-dropout) for lstm in LSTMCells]\n",
    "\n",
    "dropMultiRNNCell = tf.compat.v1.nn.rnn_cell.MultiRNNCell(dropLSTMCells)\n",
    "multiRNNCell = tf.compat.v1.nn.rnn_cell.MultiRNNCell(LSTMCells)\n",
    "\n",
    "# Defining weights and bias for the model\n",
    "w = tf.compat.v1.get_variable('w',shape=[hiddenNodeCount[-1], 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1)\n",
    "b = tf.compat.v1.get_variable('b',initializer=initializer(shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating and storing both cell and hidden state\n",
    "cellState, hiddenState = [],[]\n",
    "initialState = []\n",
    "for i in range(layerCount):\n",
    "  cellState.append(tf.Variable(tf.zeros([sizeOfBatch, hiddenNodeCount[i]]), trainable=False))\n",
    "  hiddenState.append(tf.Variable(tf.zeros([sizeOfBatch, hiddenNodeCount[i]]), trainable=False))\n",
    "  initialState.append(tf.compat.v1.nn.rnn_cell.LSTMStateTuple(cellState[i], hiddenState[i]))\n",
    "\n",
    "inputs = tf.concat([tf.expand_dims(t,0) for t in trainingInputs],axis=0)\n",
    "\n",
    "LSTMOutputs, state = tf.compat.v1.nn.dynamic_rnn(\n",
    "    dropMultiRNNCell, inputs, initial_state=tuple(initialState),\n",
    "    time_major = True, dtype=tf.float32)\n",
    "\n",
    "# Feeding the sate to get predictions\n",
    "LSTMOutputs = tf.reshape(LSTMOutputs, [sizeOfBatch*futureTimeSteps,hiddenNodeCount[-1]])\n",
    "\n",
    "allOutputs = tf.compat.v1.nn.xw_plus_b(LSTMOutputs,w,b)\n",
    "\n",
    "split_outputs = tf.split(allOutputs,futureTimeSteps,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating loss which is Mean Squared Error\n",
    "loss = 0.0\n",
    "with tf.compat.v1.control_dependencies([tf.compat.v1.assign(cellState[i], state[i][0]) for i in range(layerCount)]+\n",
    "                             [tf.compat.v1.assign(hiddenState[i], state[i][1]) for i in range(layerCount)]):\n",
    "  for k in range(futureTimeSteps):\n",
    "    loss += tf.reduce_mean(0.5*(split_outputs[k]-trainingOutputs[k])**2)\n",
    "\n",
    "# Learning rate decay\n",
    "Gstep = tf.Variable(0, trainable=False)\n",
    "GStepInc = tf.compat.v1.assign(Gstep,Gstep + 1)\n",
    "tfLr = tf.compat.v1.placeholder(shape=None,dtype=tf.float32)\n",
    "tfMinLr = tf.compat.v1.placeholder(shape=None,dtype=tf.float32)\n",
    "\n",
    "lr = tf.maximum(tf.compat.v1.train.exponential_decay(tfLr, Gstep, decay_steps=1, decay_rate=0.5, staircase=True),tfMinLr)\n",
    "\n",
    "# Defining optimizer nad used Adam \n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(lr)\n",
    "grads, v = zip(*optimizer.compute_gradients(loss))\n",
    "grads, _ = tf.clip_by_global_norm(grads, 5.0)\n",
    "optimizer = optimizer.apply_gradients(zip(grads, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampleInputs = tf.compat.v1.placeholder(tf.float32, shape=[1,D])\n",
    "\n",
    "# Storing LSTM state which will be used later for predicting output\n",
    "\n",
    "cell, hidden, sampleInitialState = [],[],[]\n",
    "for i in range(layerCount):\n",
    "  cell.append(tf.Variable(tf.zeros([1, hiddenNodeCount[i]]), trainable=False))\n",
    "  hidden.append(tf.Variable(tf.zeros([1, hiddenNodeCount[i]]), trainable=False))\n",
    "  sampleInitialState.append(tf.compat.v1.nn.rnn_cell.LSTMStateTuple(cell[i],hidden[i]))\n",
    "\n",
    "#   Resetting both state variables\n",
    "sampleStateReset = tf.group(*[tf.compat.v1.assign(cell[i],tf.zeros([1, hiddenNodeCount[i]])) for i in range(layerCount)],\n",
    "                            *[tf.compat.v1.assign(hidden[i],tf.zeros([1, hiddenNodeCount[i]])) for i in range(layerCount)])\n",
    "\n",
    "sampleOutput, sampleState = tf.compat.v1.nn.dynamic_rnn(multiRNNCell, \n",
    "                                                            tf.expand_dims(sampleInputs,0),\n",
    "                                                            initial_state=tuple(sampleInitialState),\n",
    "                                                            time_major = True,\n",
    "                                                            dtype=tf.float32)\n",
    "\n",
    "with tf.control_dependencies([tf.compat.v1.assign(cell[i],sampleState[i][0]) for i in range(layerCount)]+\n",
    "                              [tf.compat.v1.assign(hidden[i],sampleState[i][1]) for i in range(layerCount)]):  \n",
    "  predictionSample = tf.compat.v1.nn.xw_plus_b(tf.reshape(sampleOutput,[1,-1]), w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
       "  warnings.warn(&#39;An interactive session is already active. This can &#39;\n",
       "[========== Epoch 1/30 ==========]\n",
       "Average Validation Loss: 0.361951\n",
       "MSE of the Testing Data: 0.052015\n",
       "[========== Epoch 2/30 ==========]\n",
       "Average Validation Loss: 0.138214\n",
       "MSE of the Testing Data: 0.038964\n",
       "[========== Epoch 3/30 ==========]\n",
       "Average Validation Loss: 0.101834\n",
       "MSE of the Testing Data: 0.040723\n",
       "[========== Epoch 4/30 ==========]\n",
       "Average Validation Loss: 0.081227\n",
       "MSE of the Testing Data: 0.051159\n",
       "[========== Epoch 5/30 ==========]\n",
       "Average Validation Loss: 0.073423\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.059973\n",
       "[========== Epoch 6/30 ==========]\n",
       "Average Validation Loss: 0.065542\n",
       "MSE of the Testing Data: 0.060181\n",
       "[========== Epoch 7/30 ==========]\n",
       "Average Validation Loss: 0.063151\n",
       "MSE of the Testing Data: 0.054310\n",
       "[========== Epoch 8/30 ==========]\n",
       "Average Validation Loss: 0.063651\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.065558\n",
       "[========== Epoch 9/30 ==========]\n",
       "Average Validation Loss: 0.060338\n",
       "MSE of the Testing Data: 0.053893\n",
       "[========== Epoch 10/30 ==========]\n",
       "Average Validation Loss: 0.060317\n",
       "MSE of the Testing Data: 0.051545\n",
       "[========== Epoch 11/30 ==========]\n",
       "Average Validation Loss: 0.058954\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.053459\n",
       "[========== Epoch 12/30 ==========]\n",
       "Average Validation Loss: 0.055911\n",
       "MSE of the Testing Data: 0.053520\n",
       "[========== Epoch 13/30 ==========]\n",
       "Average Validation Loss: 0.057880\n",
       "MSE of the Testing Data: 0.052734\n",
       "[========== Epoch 14/30 ==========]\n",
       "Average Validation Loss: 0.057940\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.050429\n",
       "[========== Epoch 15/30 ==========]\n",
       "Average Validation Loss: 0.055376\n",
       "MSE of the Testing Data: 0.049988\n",
       "[========== Epoch 16/30 ==========]\n",
       "Average Validation Loss: 0.056449\n",
       "MSE of the Testing Data: 0.052779\n",
       "[========== Epoch 17/30 ==========]\n",
       "Average Validation Loss: 0.055098\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.053503\n",
       "[========== Epoch 18/30 ==========]\n",
       "Average Validation Loss: 0.055683\n",
       "MSE of the Testing Data: 0.049396\n",
       "[========== Epoch 19/30 ==========]\n",
       "Average Validation Loss: 0.053801\n",
       "MSE of the Testing Data: 0.051862\n",
       "[========== Epoch 20/30 ==========]\n",
       "Average Validation Loss: 0.056903\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.049897\n",
       "[========== Epoch 21/30 ==========]\n",
       "Average Validation Loss: 0.053802\n",
       "MSE of the Testing Data: 0.052760\n",
       "[========== Epoch 22/30 ==========]\n",
       "Average Validation Loss: 0.053387\n",
       "MSE of the Testing Data: 0.052145\n",
       "[========== Epoch 23/30 ==========]\n",
       "Average Validation Loss: 0.055560\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.051476\n",
       "[========== Epoch 24/30 ==========]\n",
       "Average Validation Loss: 0.053673\n",
       "MSE of the Testing Data: 0.051765\n",
       "[========== Epoch 25/30 ==========]\n",
       "Average Validation Loss: 0.055190\n",
       "MSE of the Testing Data: 0.052162\n",
       "[========== Epoch 26/30 ==========]\n",
       "Average Validation Loss: 0.053371\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.051490\n",
       "[========== Epoch 27/30 ==========]\n",
       "Average Validation Loss: 0.054452\n",
       "MSE of the Testing Data: 0.051216\n",
       "[========== Epoch 28/30 ==========]\n",
       "Average Validation Loss: 0.055365\n",
       "MSE of the Testing Data: 0.051928\n",
       "[========== Epoch 29/30 ==========]\n",
       "Average Validation Loss: 0.055206\n",
       "Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5\n",
       "MSE of the Testing Data: 0.052122\n",
       "[========== Epoch 30/30 ==========]\n",
       "Average Validation Loss: 0.055359\n",
       "MSE of the Testing Data: 0.052083\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and predicting close values of AAL stocks using LSTM\n",
    "NoOfEpochs = 30\n",
    "test_interval = 1\n",
    "\n",
    "stepsPerPredicition = 10\n",
    "\n",
    "trainingLength = trainingData.size\n",
    "\n",
    "# Storing MSE losses for training and testing\n",
    "training_MSELoss = []\n",
    "testing_MSELoss = []\n",
    "predictions = []\n",
    "lossHistory = {}\n",
    "\n",
    "session = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "tf.compat.v1.global_variables_initializer().run()\n",
    "\n",
    "# Keeping track of changes in loss\n",
    "lossCount = 0\n",
    "lossThreshold = 2\n",
    "avgLoss = 0\n",
    "\n",
    "dataGen = DataGen(trainingData,sizeOfBatch,futureTimeSteps)\n",
    "\n",
    "xAxis = []\n",
    "\n",
    "# Test predictions from here\n",
    "test_points_seq = np.arange(1007, 1258-5, 10).tolist()\n",
    "\n",
    "for epoch in range(NoOfEpochs):       \n",
    "\n",
    "# Training\n",
    "    for s in range(trainingLength//sizeOfBatch):\n",
    "\n",
    "        data_, labels_ = dataGen.unpack_future_batches()\n",
    "\n",
    "        dict = {}\n",
    "        for i,(data,label) in enumerate(zip(data_,labels_)):            \n",
    "            dict[trainingInputs[i]] = data.reshape(-1,1)\n",
    "            dict[trainingOutputs[i]] = label.reshape(-1,1)\n",
    "\n",
    "        dict.update({tfLr: 0.0001, tfMinLr:0.000001})\n",
    "\n",
    "        _, l = session.run([optimizer, loss], feed_dict=dict)\n",
    "\n",
    "        avgLoss += l\n",
    "\n",
    "# Validation\n",
    "    if (epoch + 1) % test_interval == 0:\n",
    "\n",
    "      avgLoss = avgLoss/(test_interval*(trainingLength//sizeOfBatch))\n",
    "\n",
    "      # Calculating ahe average loss\n",
    "      if (epoch + 1)%test_interval==0:\n",
    "        print(\"[========== Epoch %d/%d ==========]\" % (epoch + 1, NoOfEpochs))\n",
    "        print(\"Average Validation Loss: %f\" % (avgLoss))\n",
    "\n",
    "      training_MSELoss.append(avgLoss)\n",
    "\n",
    "      avgLoss = 0\n",
    "\n",
    "      predictionsSeq = []\n",
    "\n",
    "      MSETestLoss = []\n",
    "\n",
    "# Calculating Predictions\n",
    "      for w in test_points_seq:\n",
    "        MSE_Testloss = 0.0\n",
    "        ourPredictions = []\n",
    "\n",
    "        if (epoch + 1) - test_interval==0:\n",
    "           x_Axis_=[]\n",
    "\n",
    "# Sending this to recent state of stock prices\n",
    "        for j in range(w-futureTimeSteps+1,w-1):\n",
    "          currentPrice = closingData[j]\n",
    "          dict[sampleInputs] = np.array(currentPrice).reshape(1,1)    \n",
    "          _ = session.run(predictionSample, feed_dict=dict)\n",
    "\n",
    "        dict = {}\n",
    "\n",
    "        currentPrice = closingData[w-1]\n",
    "\n",
    "        dict[sampleInputs] = np.array(currentPrice).reshape(1,1)\n",
    "\n",
    "        for p in range(stepsPerPredicition):\n",
    "          pred = session.run(predictionSample,feed_dict=dict)\n",
    "          ourPredictions.append(pred.item())\n",
    "          dict[sampleInputs] = np.asarray(pred).reshape(-1,1)\n",
    "\n",
    "          if (epoch + 1)-test_interval==0:\n",
    "            x_Axis_.append(w+p)\n",
    "            \n",
    "          MSE_Testloss += 0.5*(pred-closingData[w+p])**2\n",
    "\n",
    "        session.run(sampleStateReset)\n",
    "        predictionsSeq.append(np.array(ourPredictions))\n",
    "\n",
    "        MSE_Testloss /= stepsPerPredicition\n",
    "        MSETestLoss.append(MSE_Testloss)\n",
    "\n",
    "        if (epoch + 1)-test_interval==0:\n",
    "          xAxis.append(x_Axis_)\n",
    "\n",
    "      current_test_mse = np.mean(MSETestLoss)\n",
    "\n",
    "# Performing Decay of Learning Rate\n",
    "      if len(testing_MSELoss)>0 and current_test_mse > min(testing_MSELoss):\n",
    "          lossCount += 1\n",
    "      else:\n",
    "          lossCount = 0\n",
    "\n",
    "      if lossCount > lossThreshold :\n",
    "            session.run(GStepInc)\n",
    "            lossCount = 0\n",
    "            print('Because the test error rate has not increased in the last 2 epochs we are decreasing learning rate by 0.5')\n",
    "\n",
    "      testing_MSELoss.append(current_test_mse)\n",
    "      print('MSE of the Testing Data: %f'%np.mean(MSETestLoss))\n",
    "#       Storing loss history to use it in next step for plotting the loss for best epoch\n",
    "      lossHistory[epoch+1] =  np.mean(MSETestLoss)\n",
    "      predictions.append(predictionsSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecting epoch with least loss\n",
    "epochWithLeastLoss = min(lossHistory.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Storing predictions from the best epoch\n",
    "preds = []\n",
    "for xval,yval in zip(xAxis,predictions[epochWithLeastLoss-1]):\n",
    "  preds.append(yval)\n",
    "  \n",
    "flattened = [val for sublist in preds for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuzlizing true values and predicted values of test data\n",
    "plt.figure(figsize = (18,9))\n",
    "\n",
    "plt.plot(testingData, label=\"True\")\n",
    "plt.plot(flattened, label=\"Predicted\")\n",
    "plt.title('True Values vs Predicted Close Prices',fontsize=18)\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Close Price', fontsize=15)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing loss for each epoch\n",
    "plt.figure(figsize = (18,9))\n",
    "plt.plot(lossHistory.values())\n",
    "plt.title('MSE Test Loss for each Epoch',fontsize=18)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('MSE', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Mean Absolute Error 0.22561\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating MAE\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "loss = mae(testingData[:-2], flattened)\n",
    "print(\"Mean Absolute Error\",loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Mean Squared Error 0.038963865\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating MSE\n",
    "mse = min(lossHistory.items(), key=operator.itemgetter(1))[1]\n",
    "print(\"Mean Squared Error\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Mean Squared Logarithmic Error 0.033963103\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating MSLE\n",
    "msle = tf.keras.losses.MSLE(testingData[:-2], flattened)\n",
    "print(\"Mean Squared Logarithmic Error\", msle.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  },
  "name": "Big Data Project(LSTM)",
  "notebookId": 2225259216550842
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
